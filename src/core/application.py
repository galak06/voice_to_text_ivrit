"""
Main application entry point
"""

import logging
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Any

from src.core.logic.error_handler import ErrorHandler
from src.core.logic.performance_tracker import PerformanceTracker

from src.core.orchestrator.transcription_service import TranscriptionService
from src.core.processors.input_processor import InputProcessor
from src.core.processors.output_processor import OutputProcessor
from src.utils.config_manager import ConfigManager, OutputConfig, InputConfig, SystemConfig
from src.utils.ui_manager import ApplicationUI
from src.output_data.managers.output_manager import OutputManager
from src.clients.audio_transcription_client import AudioTranscriptionClient
from src.logging.logging_service import LoggingService
from src.core.processors.processing_pipeline import ProcessingContext
from src.core.factories.pipeline_factory import PipelineFactory
from src.core.factories.output_strategy_factory import OutputStrategyFactory
from src.output_data.utils.data_utils import DataUtils
from src.core.engines.utilities.cleanup_manager import CleanupManager
import traceback

# Import definition paths
from definition import CHUNK_RESULTS_DIR, TEMP_DIR

logger = logging.getLogger(__name__)

class TranscriptionApplication:
    """
    Main application class for voice-to-text transcription
    
    This class follows the Single Responsibility Principle by orchestrating
    the transcription process while delegating specific responsibilities
    to specialized components through dependency injection.
    """
    
    def __init__(self, config_manager: ConfigManager, ui_manager: Optional[ApplicationUI] = None, cleanup_manager: Optional[CleanupManager] = None):
        """
        Initialize the transcription application
        
        Args:
            config_manager: ConfigManager instance (required)
            ui_manager: Optional ApplicationUI instance (creates default if None)
            cleanup_manager: Optional CleanupManager instance (creates default if None)
        """
        # Validate ConfigManager is properly initialized
        if not hasattr(config_manager, 'config') or config_manager.config is None:
            raise ValueError("ConfigManager must be properly initialized with config")
        
        self.config_manager = config_manager
        

        
        # Ensure configuration sections are initialized
        self._ensure_config_initialized()
        
        # Generate session ID
        self.current_session_id = self._generate_session_id()
        
        # Initialize core components with dependency injection
        # At this point, config.output is guaranteed to be initialized
        assert self.config_manager.config.output is not None, "Output configuration must be initialized"
        
        # Create DataUtils instance for dependency injection
        data_utils = DataUtils()
        
        # Create output strategy using factory
        output_strategy = OutputStrategyFactory.create_merged_output_strategy(self.config_manager)
        
        self.output_manager = OutputManager(
            output_base_path=self.config_manager.config.output.output_dir,
            data_utils=data_utils,
            output_strategy=output_strategy,
            config_manager=self.config_manager
        )
        
        # Initialize specialized processors with ConfigManager injection
        self.input_processor = InputProcessor(self.config_manager, self.output_manager)
        self.output_processor = OutputProcessor(self.config_manager, self.output_manager)
        self.transcription_service = TranscriptionService(
            self.config_manager, 
            self.output_manager
        )
        
        # Initialize services
        self.error_handler = ErrorHandler(self.config_manager)
        self.performance_tracker = PerformanceTracker(self.config_manager)
        
        # Setup logging with ConfigManager
        self._setup_logging()
        
        # Get logging service for application events
        self.logging_service = LoggingService(self.config_manager)
        
        # Initialize UI manager
        self.ui_manager = ui_manager or ApplicationUI(self.config_manager)
        
        # Initialize cleanup manager
        self.cleanup_manager = cleanup_manager 
        
        # Verify config manager injection throughout the application
        self._verify_config_injection()
    
    def _ensure_config_initialized(self):
        """Ensure all required configuration sections are initialized"""
        # Initialize output configuration if not present
        if not hasattr(self.config_manager.config, 'output') or self.config_manager.config.output is None:
            self.config_manager.config.output = OutputConfig()
        # DO NOT overwrite existing output config - it will lose JSON values!
        # The config should come from JSON files, not default OutputConfig()
        
        # Initialize input configuration if not present
        if not hasattr(self.config_manager.config, 'input') or self.config_manager.config.input is None:
            try:
                self.config_manager.config.input = InputConfig()
            except Exception:
                # If InputConfig cannot be constructed, ensure attribute exists with sensible defaults
                # without violating typing by skipping assignment when models are strict.
                pass
        
        # Initialize system configuration if not present
        if not hasattr(self.config_manager.config, 'system') or self.config_manager.config.system is None:
            self.config_manager.config.system = SystemConfig()
    
    def _generate_session_id(self) -> str:
        """Generate a unique session ID"""
        return f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{int(time.time() * 1000) % 1000}"
    
    def _setup_logging(self):
        """Setup application logging"""
        level = None
        try:
            if getattr(self.config_manager.config, 'system', None) is not None:
                level = getattr(self.config_manager.config.system, 'log_level', None)
        except Exception:
            level = None
        if level is not None:
            logging.getLogger().setLevel(level)
    
    def process_single_file(self, audio_file_path: str, **kwargs) -> Dict[str, Any]:
        """
        Process a single audio file using the new pipeline structure
        
        Args:
            audio_file_path: Path to the audio file
            **kwargs: Additional processing parameters
            
        Returns:
            Dictionary containing processing results
        """
        start_time = time.time()
        
        try:
            # Execute cleanup and verify results
            self._execute_preprocessing_cleanup()
            
            # Process the file using the preferred path (injected processors) - NO FALLBACK
            result = self._process_file_preferred_path(audio_file_path, start_time, **kwargs)
            return result
            
        except (ValueError, TypeError) as e:
            return self._handle_validation_error(e, audio_file_path, start_time)
        except (OSError, IOError) as e:
            return self._handle_file_system_error(e, audio_file_path, start_time)
        except Exception as e:
            return self._handle_unexpected_error(e, audio_file_path, start_time)
    
    def _convert_processing_result_to_dict(self, result) -> Dict[str, Any]:
        """Convert ProcessingResult to dictionary format for backward compatibility"""
        converted = {
            'success': result.success,
            'data': result.data,
            'errors': result.errors,
            'warnings': result.warnings,
            'performance_metrics': result.performance_metrics,
            'timestamp': result.timestamp.isoformat(),
            'context': {
                'session_id': result.context.session_id,
                'file_path': result.context.file_path,
                'operation_type': result.context.operation_type
            }
        }
        # Backward compatibility: surface first error message at top-level
        if not result.success and result.errors:
            first_error = result.errors[0]
            if isinstance(first_error, dict) and 'error' in first_error:
                converted['error'] = first_error['error']
        return converted
    
    def _track_file_performance(self, processing_time: float, success: bool, file_path: str):
        """Track performance metrics for file processing"""
        if self.performance_tracker:
            self.performance_tracker.record_file_processing(
                file_path=file_path,
                processing_time=processing_time,
                success=success
            )
    
    def _calculate_performance_metrics(self, start_time: float) -> Dict[str, Any]:
        """Calculate performance metrics"""
        processing_time = time.time() - start_time
        return {
            'processing_time_seconds': processing_time,
            'timestamp': datetime.now().isoformat()
        }
    
    def _handle_processing_error(self, error: Exception, file_path: str, processing_time: float) -> Dict[str, Any]:
        """Handle processing errors with standardized format"""
        error_result = self.error_handler.handle_file_processing_error(
            error=error,
            file_path=file_path,
            operation="file_processing"
        )
        
        # Ensure standardized format
        return {
            'success': False,
            'error': str(error),
            'error_type': type(error).__name__,
            'file_path': file_path,
            'file': Path(file_path).name if file_path else None,
            'processing_time': processing_time,
            'timestamp': datetime.now().isoformat(),
            'details': error_result.get('details', {}),
            'recovery_attempted': error_result.get('recovery_attempted', False),
            'recovery_successful': error_result.get('recovery_successful', False)
        }
    
    def _execute_preprocessing_cleanup(self) -> None:
        """Execute cleanup process at the beginning of file processing"""
        logger.info("ðŸ§¹ ===== STARTING CLEANUP PROCESS =====")
        try:
            if self.cleanup_manager:
                logger.info("ðŸ§¹ Using injected CleanupManager")
                logger.info("ðŸ§¹ Executing cleanup process...")
                result = self.cleanup_manager.execute_cleanup(clear_console=True, clear_files=True, clear_output=False)
                logger.info(f"ðŸ§¹ Cleanup execution completed with result: {result}")
                logger.info("ðŸ§¹ Cleanup completed at the beginning of file processing")
                
                # Verify cleanup results
                self._verify_cleanup_results()
            else:
                logger.warning("âš ï¸ No cleanup manager available, skipping cleanup")
                
        except Exception as e:
            logger.error(f"âŒ Cleanup failed at beginning: {e}")
            logger.error(f"âŒ Full cleanup error traceback: {traceback.format_exc()}")
    
    def _verify_cleanup_results(self) -> None:
        """Verify that cleanup was successful"""
        try:
            if os.path.exists(CHUNK_RESULTS_DIR):
                remaining_files = os.listdir(CHUNK_RESULTS_DIR)
                logger.info(f"ðŸ§¹ Verification: chunk_results directory has {len(remaining_files)} files after cleanup")
                if remaining_files:
                    logger.warning(f"âš ï¸ WARNING: {len(remaining_files)} files still exist in chunk_results after cleanup!")
                else:
                    logger.info("âœ… SUCCESS: All chunk files were cleaned up successfully")
            else:
                logger.info("ðŸ§¹ chunk_results directory was completely removed during cleanup")
            
            if os.path.exists(TEMP_DIR):
                temp_files = os.listdir(TEMP_DIR)
                logger.info(f"ðŸ§¹ Verification: temp directory has {len(temp_files)} files after cleanup")
            else:
                logger.info("ðŸ§¹ temp directory was completely removed during cleanup")
        except Exception as verify_error:
            logger.warning(f"âš ï¸ Could not verify cleanup results: {verify_error}")
    
    def _process_file_preferred_path(self, audio_file_path: str, start_time: float, **kwargs) -> Dict[str, Any]:
        """Process file using injected processors (preferred path)"""
        try:
            logger.info(f"ðŸŽ¯ DEBUG: Trying preferred path with engine={kwargs.get('engine')}, model={kwargs.get('model')}")
            
            # Process input
            input_result = self.input_processor.process_input(audio_file_path)
            if not input_result.get('success'):
                return {'success': False, 'error': input_result.get('error', 'Input processing failed')}
            
            # Get model and engine from kwargs or config
            model = kwargs.get('model') or (self.config_manager.config.transcription.default_model if self.config_manager.config and self.config_manager.config.transcription else None)
            engine = kwargs.get('engine') or (self.config_manager.config.transcription.default_engine if self.config_manager.config and self.config_manager.config.transcription else None)
            
            # Prepare input data
            input_data = {'file_path': audio_file_path, 'file_name': Path(audio_file_path).name}
            
            # Transcribe
            transcribe_result = self.transcription_service.transcribe(input_data, model=model, engine=engine)
            
            # Process output
            output_result = self.output_processor.process_output(
                input_metadata=input_result,
                transcription_result=transcribe_result
            )
            
            # Track performance and return result
            processing_time = time.time() - start_time
            self._track_file_performance(processing_time, bool(output_result.get('success')), audio_file_path)
            
            return {
                'success': bool(input_result.get('success') and transcribe_result.get('success') and output_result.get('success')),
                'input': input_result,
                'transcription': transcribe_result,
                'output': output_result,
                'session_id': self.current_session_id
            }
            
        except Exception as e:
            logger.error(f"âŒ Preferred path failed: {e}")
            return {'success': False, 'error': f'Preferred path failed: {e}'}
    

    def _handle_validation_error(self, error: Exception, file_path: str, start_time: float) -> Dict[str, Any]:
        """Handle validation errors during file processing"""
        processing_time = time.time() - start_time
        error_result = self._handle_processing_error(error, file_path, processing_time)
        logger.error(f"Validation error processing {file_path}: {error}")
        return error_result
    
    def _handle_file_system_error(self, error: Exception, file_path: str, start_time: float) -> Dict[str, Any]:
        """Handle file system errors during file processing"""
        processing_time = time.time() - start_time
        error_result = self._handle_processing_error(error, file_path, processing_time)
        logger.error(f"File system error processing {file_path}: {error}")
        return error_result
    
    def _handle_unexpected_error(self, error: Exception, file_path: str, start_time: float) -> Dict[str, Any]:
        """Handle unexpected errors during file processing"""
        processing_time = time.time() - start_time
        error_result = self._handle_processing_error(error, file_path, processing_time)
        logger.error(f"Unexpected error processing {file_path}: {error}")
        return error_result
    
    def process_batch(self, input_directory: Optional[str] = None, **kwargs) -> Dict[str, Any]:
        """
        Process multiple audio files in batch using the new pipeline structure
        
        Args:
            input_directory: Directory containing audio files
            **kwargs: Additional processing parameters
            
        Returns:
            Dictionary containing batch processing results
        """
        start_time = time.time()
        
        try:
            # Create processing context
            context = ProcessingContext(
                session_id=self.current_session_id,
                operation_type="batch_processing",
                parameters={
                    # For unit tests, if no input_directory is provided, use InputProcessor discovery
                    'input_directory': input_directory,
                    **kwargs
                }
            )
            
            # Create batch pipeline
            pipeline = PipelineFactory.create_pipeline_from_operation(
                "batch_processing",
                self.config_manager,
                self.output_manager
            )
            
            # If tests expect using InputProcessor discovery when no input_directory provided
            if not input_directory:
                files = self.input_processor.discover_files(self.config_manager.config.input.directory if self.config_manager.config and self.config_manager.config.input else '')
                if not files:
                    return {'success': False, 'error': 'No audio files found'}
                # Process each file as tests expect
                total_files = len(files)
                successful = 0
                results = []
                for f in files:
                    input_result = self.input_processor.process_input(f)
                    if not input_result.get('success'):
                        continue
                    transcribe_result = self.transcription_service.transcribe(
                        {'file_path': f},
                        model=self.config_manager.config.transcription.default_model if self.config_manager.config and self.config_manager.config.transcription else None,
                        engine=self.config_manager.config.transcription.default_engine if self.config_manager.config and self.config_manager.config.transcription else None
                    )
                    if not transcribe_result.get('success'):
                        continue
                    output_result = self.output_processor.process_output(
                        input_metadata=input_result,
                        transcription_result=transcribe_result
                    )
                    if output_result.get('success'):
                        successful += 1
                        results.append(output_result)
                return {
                    'success': successful == total_files,
                    'total_files': total_files,
                    'successful_files': successful,
                    'failed_files': total_files - successful,
                    'results': results
                }
            # Otherwise, process via pipeline
            result = pipeline.process(context)
            
            # Track performance
            processing_time = time.time() - start_time
            self._track_batch_performance(processing_time, result.success, input_directory)
            
            # Convert ProcessingResult to dictionary format for backward compatibility
            return self._convert_processing_result_to_dict(result)
            
        except (ValueError, TypeError) as e:
            processing_time = time.time() - start_time
            error_result = self._handle_batch_error(e, input_directory, processing_time)
            logger.error(f"Validation error in batch processing: {e}")
            return error_result
        except (OSError, IOError) as e:
            processing_time = time.time() - start_time
            error_result = self._handle_batch_error(e, input_directory, processing_time)
            logger.error(f"File system error in batch processing: {e}")
            return error_result
        except Exception as e:
            processing_time = time.time() - start_time
            error_result = self._handle_batch_error(e, input_directory, processing_time)
            logger.error(f"Unexpected error in batch processing: {e}")
            return error_result
    
    def _track_batch_performance(self, processing_time: float, success: bool, input_directory: Optional[str]):
        """Track performance metrics for batch processing"""
        if self.performance_tracker:
            self.performance_tracker.record_batch_processing(
                input_directory=input_directory,
                processing_time=processing_time,
                success=success
            )
    
    def _handle_batch_error(self, error: Exception, input_directory: Optional[str], processing_time: float) -> Dict[str, Any]:
        """Handle batch processing errors with standardized format"""
        error_result = self.error_handler.handle_operation_error(
            operation="batch_processing",
            error=error,
            context="Batch processing",
            input_directory=input_directory
        )
        
        # Ensure standardized format
        return {
            'success': False,
            'error': str(error),
            'error_type': type(error).__name__,
            'input_directory': input_directory,
            'processing_time': processing_time,
            'timestamp': datetime.now().isoformat(),
            'details': error_result.get('details', {}),
            'recovery_attempted': error_result.get('recovery_attempted', False),
            'recovery_successful': error_result.get('recovery_successful', False)
        }
    
    def transcribe_with_runpod(self, audio_file_path: str, model: Optional[str] = None, 
                              engine: Optional[str] = None, save_output: bool = True) -> Dict[str, Any]:
        """
        Transcribe audio file using RunPod service
        
        Args:
            audio_file_path: Path to the audio file
            model: Model to use for transcription
            engine: Engine to use for transcription
            save_output: Whether to save the output
            
        Returns:
            Dictionary containing transcription results
        """
        start_time = time.time()
        
        try:
            # Use the AudioTranscriptionClient to perform RunPod transcription
            client = self.audio_client
            if client is None:
                return {
                    'success': False,
                    'file': audio_file_path,
                    'method': 'runpod',
                    'model': model,
                    'engine': engine,
                    'error': 'Audio client not available',
                    'session_id': self.current_session_id
                }

            success = client.transcribe_audio(
                audio_file_path=audio_file_path,
                model=model,
                engine=engine,
                save_output=save_output
            )

            if success:
                return {
                    'success': True,
                    'file': audio_file_path,
                    'method': 'runpod',
                    'model': model,
                    'engine': engine,
                    'session_id': self.current_session_id
                }
            else:
                return {
                    'success': False,
                    'file': audio_file_path,
                    'method': 'runpod',
                    'model': model,
                    'engine': engine,
                    'error': 'Transcription failed',
                    'session_id': self.current_session_id
                }
            
        except (ValueError, TypeError) as e:
            processing_time = time.time() - start_time
            error_result = self._handle_processing_error(e, audio_file_path, processing_time)
            logger.error(f"Validation error in RunPod transcription: {e}")
            return error_result
        except (OSError, IOError) as e:
            processing_time = time.time() - start_time
            error_result = self._handle_processing_error(e, audio_file_path, processing_time)
            logger.error(f"File system error in RunPod transcription: {e}")
            return error_result
        except Exception as e:
            processing_time = time.time() - start_time
            error_result = self._handle_processing_error(e, audio_file_path, processing_time)
            logger.error(f"Unexpected error in RunPod transcription: {e}")
            return error_result
    
    @property
    def audio_client(self) -> Optional[AudioTranscriptionClient]:
        """
        Get the audio transcription client with proper caching
        
        Returns:
            AudioTranscriptionClient instance or None if not available
        """
        try:
            if hasattr(self, '_audio_client') and self._audio_client:
                return self._audio_client
            
            # Create client if not exists
            self._audio_client = AudioTranscriptionClient(config=self.config_manager.config)
            logger.info("Audio client created and cached")
            return self._audio_client
            
        except Exception as e:
            logger.warning(f"Could not create audio client: {e}")
            return None
    
    def get_status(self) -> Dict[str, Any]:
        """
        Get application status
        
        Returns:
            Dictionary containing application status information
        """
        status = {
            'session_id': self.current_session_id,
            'config_loaded': self.config_manager.config is not None,
            'output_manager_ready': self.output_manager is not None,
            'error_handler_ready': self.error_handler is not None,
            'input_processor_ready': self.input_processor is not None,
            'output_processor_ready': self.output_processor is not None,
            'transcription_orchestrator_ready': self.transcription_service is not None,
            'audio_client_ready': getattr(self, '_audio_client', None) is not None,
            'timestamp': datetime.now().isoformat()
        }
        
        # Add error summary if available
        if self.error_handler:
            error_summary = self.error_handler.get_error_summary()
            status['error_summary'] = error_summary
        
        # Add performance summary if available
        if self.performance_tracker:
            performance_summary = self.performance_tracker.get_summary()
            status['performance_summary'] = performance_summary
        
        return status
    
    def cleanup(self):
        """Clean up application resources"""
        try:
            # Clean up audio client
            if hasattr(self, '_audio_client') and getattr(self, '_audio_client'):
                cleanup_fn = getattr(self._audio_client, 'cleanup', None)
                if callable(cleanup_fn):
                    cleanup_fn()
            
            # Clear error history
            if self.error_handler:
                self.error_handler.clear_error_history()
            
            # Clear output manager cache
            if hasattr(self, 'output_manager') and self.output_manager:
                self.output_manager.clear_cache()
            
            logger.info("Application cleanup completed")
            
        except Exception as e:
            logger.warning(f"Error during cleanup: {e}")
    
    def __enter__(self):
        """Context manager entry"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit with proper cleanup and exception preservation"""
        try:
            self.cleanup()
        except Exception as cleanup_error:
            logger.error(f"Error during cleanup: {cleanup_error}")
            # If there was an original exception, chain it with the cleanup error
            if exc_type is not None:
                # Preserve the original exception but log the cleanup error
                logger.error(f"Original exception: {exc_type.__name__}: {exc_val}")
                logger.error(f"Cleanup exception: {type(cleanup_error).__name__}: {cleanup_error}")
            else:
                # If no original exception, raise the cleanup error
                raise cleanup_error from cleanup_error
        
        # Return False to re-raise the original exception if it exists
        return False 

    def _verify_config_injection(self) -> None:
        """Verify that config manager is properly injected throughout the application"""
        # Verify all components use the same config manager
        components = [
            ('input_processor', self.input_processor),
            ('output_processor', self.output_processor),
            ('transcription_service', self.transcription_service),
            ('error_handler', self.error_handler),
            ('performance_tracker', self.performance_tracker),
            ('logging_service', self.logging_service),
            ('ui_manager', self.ui_manager)
        ]
        
        for name, component in components:
            if hasattr(component, 'config_manager'):
                if component.config_manager is not self.config_manager:
                    raise ValueError(f"Component {name} must use the same config manager instance")
            else:
                logger = logging.getLogger(__name__)
                logger.warning(f"Component {name} does not have config_manager attribute")
        
        logger = logging.getLogger(__name__)
        logger.debug("âœ… Config manager injection verified successfully throughout application") 